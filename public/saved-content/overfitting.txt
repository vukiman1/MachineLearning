Tuyệt vời! Dưới đây là nội dung học tập chi tiết về Overfitting và Underfitting trong Machine Learning, được thiết kế để dễ hiểu và có nhiều ví dụ minh họa.

# Overfitting và Underfitting trong Machine Learning

Trong Machine Learning, mục tiêu chính là xây dựng một mô hình có khả năng **tổng quát hóa** tốt, tức là có thể dự đoán chính xác trên dữ liệu mới chưa từng thấy.  Tuy nhiên, đôi khi mô hình của chúng ta lại gặp phải hai vấn đề phổ biến: Overfitting (Quá khớp) và Underfitting (Thiếu khớp).  Hiểu rõ hai vấn đề này và cách khắc phục chúng là vô cùng quan trọng để xây dựng mô hình Machine Learning hiệu quả.

## 1. Overfitting (Quá Khớp)

### 1.1. Định nghĩa

Overfitting xảy ra khi mô hình học quá kỹ dữ liệu huấn luyện (training data), đến mức nó bắt đầu "học thuộc lòng" cả những nhiễu (noise) và các mẫu không quan trọng trong dữ liệu đó.  Kết quả là, mô hình hoạt động rất tốt trên dữ liệu huấn luyện, đạt độ chính xác cao, nhưng lại hoạt động kém trên dữ liệu mới (test data) hoặc dữ liệu thực tế.  Nói cách khác, mô hình không có khả năng tổng quát hóa tốt.

### 1.2. Nguyên nhân

*   **Mô hình quá phức tạp:**  Mô hình có quá nhiều tham số (ví dụ: mạng neural với nhiều lớp ẩn và nhiều neurons, cây quyết định sâu) có thể "nhớ" dữ liệu huấn luyện một cách dễ dàng.
*   **Dữ liệu huấn luyện quá ít:**  Khi có ít dữ liệu, mô hình dễ bị ảnh hưởng bởi các mẫu ngẫu nhiên và nhiễu trong dữ liệu.
*   **Huấn luyện quá lâu:**  Tiếp tục huấn luyện mô hình sau khi nó đã đạt được độ chính xác cao trên dữ liệu huấn luyện có thể dẫn đến việc nó bắt đầu học thuộc lòng dữ liệu.
*   **Các đặc trưng (features) không phù hợp:**  Sử dụng quá nhiều đặc trưng không liên quan hoặc nhiễu có thể làm cho mô hình tập trung vào những thông tin không quan trọng.

### 1.3. Cách nhận biết Overfitting

*   **Độ chính xác cao trên dữ liệu huấn luyện, độ chính xác thấp trên dữ liệu kiểm tra (validation/test data):**  Đây là dấu hiệu rõ ràng nhất.
*   **Khoảng cách lớn giữa độ chính xác trên dữ liệu huấn luyện và dữ liệu kiểm tra.**
*   **Đồ thị học tập (learning curve) cho thấy độ chính xác trên dữ liệu huấn luyện tiếp tục tăng, trong khi độ chính xác trên dữ liệu kiểm tra bắt đầu giảm hoặc ổn định.**

**Ví dụ đồ thị learning curve cho Overfitting:**

```
Training Accuracy:  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                                                                    ^
Validation Accuracy: ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^--------
```

Trong đồ thị trên, bạn có thể thấy độ chính xác trên dữ liệu huấn luyện (Training Accuracy) tiếp tục tăng, trong khi độ chính xác trên dữ liệu kiểm tra (Validation Accuracy) đạt đến một điểm rồi bắt đầu giảm. Đây là dấu hiệu điển hình của Overfitting.

### 1.4. Các kỹ thuật khắc phục Overfitting

#### 1.4.1. Regularization (Điều chuẩn)

Regularization là một kỹ thuật thêm một "hình phạt" vào hàm mất mát (loss function) để khuyến khích mô hình có các tham số nhỏ hơn. Điều này giúp giảm độ phức tạp của mô hình và ngăn chặn việc nó học thuộc lòng dữ liệu. Có hai loại regularization phổ biến:

*   **L1 Regularization (Lasso):** Thêm tổng giá trị tuyệt đối của các tham số vào hàm mất mát.  L1 regularization có xu hướng làm cho một số tham số bằng 0, do đó có thể được sử dụng để lựa chọn đặc trưng (feature selection).
    *   Công thức: `Loss = Original Loss + λ * Σ|w|` (trong đó `λ` là hệ số điều chuẩn, `w` là các tham số của mô hình)
*   **L2 Regularization (Ridge):** Thêm tổng bình phương của các tham số vào hàm mất mát.  L2 regularization làm giảm độ lớn của các tham số, nhưng không làm cho chúng bằng 0.
    *   Công thức: `Loss = Original Loss + λ * Σw²` (trong đó `λ` là hệ số điều chuẩn, `w` là các tham số của mô hình)

**Ví dụ code (Python, sử dụng scikit-learn):**

```python
from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression

# Tạo dữ liệu giả
X, y = make_regression(n_samples=100, n_features=10, noise=0.1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# L2 Regularization (Ridge)
ridge = Ridge(alpha=1.0) # alpha là hệ số điều chuẩn (lambda)
ridge.fit(X_train, y_train)
ridge_score = ridge.score(X_test, y_test)
print(f"Ridge Regression R^2 score: {ridge_score}")

# L1 Regularization (Lasso)
lasso = Lasso(alpha=0.1) # alpha là hệ số điều chuẩn (lambda)
lasso.fit(X_train, y_train)
lasso_score = lasso.score(X_test, y_test)
print(f"Lasso Regression R^2 score: {lasso_score}")
```

#### 1.4.2. Dropout

Dropout là một kỹ thuật regularization đặc biệt hữu ích cho mạng neural.  Trong quá trình huấn luyện, dropout ngẫu nhiên "tắt" một số neurons (và các kết nối của chúng) với một xác suất nhất định (ví dụ: 50%).  Điều này buộc mạng phải học các đặc trưng mạnh mẽ hơn, không phụ thuộc vào bất kỳ neuron cụ thể nào.

**Ví dụ code (Python, sử dụng TensorFlow/Keras):**

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential([
    Dense(128, activation='relu', input_shape=(10,)), # Giả sử có 10 features
    Dropout(0.5), # Tắt 50% neurons
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1) # Output layer
])

model.compile(optimizer='adam', loss='mse')
# ... Huấn luyện mô hình ...
```

#### 1.4.3. Early Stopping

Early stopping là một kỹ thuật đơn giản nhưng hiệu quả.  Trong quá trình huấn luyện, chúng ta theo dõi hiệu suất của mô hình trên một tập dữ liệu kiểm tra (validation set).  Nếu hiệu suất trên tập kiểm tra bắt đầu giảm, chúng ta dừng quá trình huấn luyện, ngay cả khi độ chính xác trên dữ liệu huấn luyện vẫn đang tăng.  Điều này giúp ngăn chặn mô hình học thuộc lòng dữ liệu huấn luyện.

#### 1.4.4. Data Augmentation (Tăng cường dữ liệu)

Data augmentation là một kỹ thuật tạo ra thêm dữ liệu huấn luyện bằng cách biến đổi dữ liệu hiện có.  Ví dụ, trong bài toán nhận dạng ảnh, chúng ta có thể xoay, lật, hoặc thay đổi độ sáng của ảnh để tạo ra các ảnh mới.  Việc tăng cường dữ liệu giúp mô hình học được các đặc trưng tổng quát hơn và ít bị ảnh hưởng bởi các biến thể nhỏ trong dữ liệu.

#### 1.4.5. Cross-Validation (Kiểm định chéo)

Cross-validation là một kỹ thuật đánh giá hiệu suất của mô hình trên nhiều tập dữ liệu khác nhau.  Trong k-fold cross-validation, chúng ta chia dữ liệu thành k phần (folds).  Chúng ta huấn luyện mô hình trên k-1 phần và đánh giá nó trên phần còn lại.  Quá trình này được lặp lại k lần, mỗi lần sử dụng một phần khác nhau làm tập kiểm tra.  Kết quả là chúng ta có k đánh giá hiệu suất, và chúng ta có thể tính trung bình các đánh giá này để có được một ước tính tổng quát hơn về hiệu suất của mô hình.  Cross-validation giúp chúng ta chọn được mô hình có khả năng tổng quát hóa tốt nhất.

## 2. Underfitting (Thiếu Khớp)

### 2.1. Định nghĩa

Underfitting xảy ra khi mô hình quá đơn giản để có thể nắm bắt được các mẫu quan trọng trong dữ liệu.  Mô hình hoạt động kém cả trên dữ liệu huấn luyện và dữ liệu kiểm tra.  Nói cách khác, mô hình không đủ khả năng để học được mối quan hệ giữa các đặc trưng và biến mục tiêu.

### 2.2. Nguyên nhân

*   **Mô hình quá đơn giản:**  Mô hình có quá ít tham số (ví dụ: mô hình tuyến tính cho dữ liệu phi tuyến tính, cây quyết định quá nông) không thể biểu diễn được sự phức tạp của dữ liệu.
*   **Dữ liệu huấn luyện không đủ tốt:**  Dữ liệu có thể chứa nhiều nhiễu, thiếu thông tin, hoặc không đại diện cho toàn bộ không gian dữ liệu.
*   **Huấn luyện quá ít:**  Mô hình chưa được huấn luyện đủ lâu để học được các mẫu quan trọng.
*   **Sử dụng các đặc trưng không phù hợp:**  Các đặc trưng không liên quan hoặc không đủ mạnh để dự đoán biến mục tiêu.

### 2.3. Cách nhận biết Underfitting

*   **Độ chính xác thấp trên cả dữ liệu huấn luyện và dữ liệu kiểm tra.**
*   **Đồ thị học tập cho thấy cả độ chính xác trên dữ liệu huấn luyện và dữ liệu kiểm tra đều thấp và không cải thiện nhiều theo thời gian.**

**Ví dụ đồ thị learning curve cho Underfitting:**

```
Training Accuracy:  ^^^^^^
                               ^
Validation Accuracy: ^^^^^^
```

Trong đồ thị trên, cả độ chính xác trên dữ liệu huấn luyện (Training Accuracy) và độ chính xác trên dữ liệu kiểm tra (Validation Accuracy) đều thấp và không tăng nhiều theo thời gian.

### 2.4. Các kỹ thuật khắc phục Underfitting

*   **Chọn mô hình phức tạp hơn:**  Sử dụng mô hình có nhiều tham số hơn, ví dụ: chuyển từ mô hình tuyến tính sang mô hình đa thức, sử dụng mạng neural sâu hơn, hoặc cây quyết định sâu hơn.
*   **Thêm các đặc trưng (features) mới:**  Tìm kiếm các đặc trưng có liên quan hơn hoặc tạo ra các đặc trưng mới từ các đặc trưng hiện có (feature engineering).
*   **Huấn luyện lâu hơn:**  Tăng số lượng epochs hoặc thời gian huấn luyện.
*   **Giảm bớt regularization:**  Nếu bạn đang sử dụng regularization, hãy giảm hệ số điều chuẩn (lambda) để cho phép mô hình học được nhiều hơn.
*   **Thu thập thêm dữ liệu:**  Nếu có thể, hãy thu thập thêm dữ liệu huấn luyện để cung cấp cho mô hình nhiều thông tin hơn.

## 3. Bảng so sánh Overfitting và Underfitting

| Đặc điểm      | Overfitting                                  | Underfitting                                 |
|--------------|----------------------------------------------|---------------------------------------------|
| Định nghĩa    | Học quá kỹ dữ liệu huấn luyện, kém tổng quát | Không học đủ dữ liệu, kém tổng quát           |
| Nguyên nhân   | Mô hình quá phức tạp, dữ liệu ít, nhiễu     | Mô hình quá đơn giản, dữ liệu không đủ tốt |
| Dấu hiệu      | Độ chính xác cao trên train, thấp trên test  | Độ chính xác thấp trên cả train và test      |
| Khắc phục     | Regularization, Dropout, Early stopping, Data Augmentation | Chọn mô hình phức tạp hơn, thêm features, huấn luyện lâu hơn |

Hy vọng nội dung này giúp bạn hiểu rõ hơn về Overfitting và Underfitting trong Machine Learning! Chúc bạn học tập tốt!
